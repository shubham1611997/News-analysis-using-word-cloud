{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=\"On 20 August 1945, the Indonesian government established the Agency for Assisting Families of War Victims (Badan Penolong Keluarga Korban Perang; abbreviated as BPKKP) and its focus was to assist the war victims and their respective family during the time of Indonesian National Revolution.In 1966, the government established the Advisory Board of Central Natural Disaster Management (Badan Pertimbangan Penanggulangan Bencana Alam Pusat; abbreviated as BP2BA) through the Presidential Decree Number 256 of 1966. The board was responsible to the Minister of Social Affairs. A year later, the Cabinet Presidium through Decree number 14/U/KEP/I/1967, established the National Coordination Team for Disaster Management (Tim Koordinasi Nasional Penanggulangan Bencana Alam; abbreviated as TKP2BA).Bakornas PB was established in 1979 to replace the Advisory Board for Natural Disaster, which was established in 1966.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s) if '.' in s else int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "def load_stop_words():\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop_words = []\n",
    "    for i in stop:\n",
    "        stop_words.append(i)\n",
    "    return stop_words\n",
    "def build_stop_word_regex():\n",
    "    stop_word_list = load_stop_words()\n",
    "    stop_word_regex_list = []\n",
    "    for word in stop_word_list:\n",
    "        word_regex = r'\\b' + word + r'(?![\\w-])'\n",
    "        stop_word_regex_list.append(word_regex)\n",
    "    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n",
    "    return stop_word_pattern\n",
    "\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Utility function to return a list of sentences.\n",
    "    @param text The text that must be split in to sentences.\n",
    "    \"\"\"\n",
    "    sentence_delimiters = re.compile(u'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s')\n",
    "    sentences = sentence_delimiters.split(text)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def separate_words(text):\n",
    "    \"\"\"9\n",
    "    Utility function to return a list of all words that are have a length greater than a specified number of characters.\n",
    "    @param text The text that must be split in to words.\n",
    "    @param min_word_return_size The minimum no of characters a word must have to be included.\n",
    "    \"\"\"\n",
    "    splitter = re.compile('\\W+')\n",
    "    words = []\n",
    "    for single_word in splitter.split(text):\n",
    "        current_word = single_word.strip().lower()\n",
    "        # leave numbers in phrase, but don't count as words, since they tend to invalidate scores of their phrases\n",
    "        if current_word != '' and not is_number(current_word):\n",
    "            words.append(current_word)\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_candidate_keywords(sentence_list, stop_word_pattern, minCharacters, maxWords):\n",
    "    phrase_list = []\n",
    "    for s in sentence_list:\n",
    "        tmp = re.sub(stop_word_pattern, '|', s.strip())\n",
    "        phrases = tmp.split(\"|\")\n",
    "        for phrase in phrases:\n",
    "            phrase = phrase.strip().lower()\n",
    "            if phrase != '' and len(phrase) >= minCharacters and len(phrase.split()) <= maxWords:\n",
    "                phrase_list.append(phrase)\n",
    "    return phrase_list\n",
    "\n",
    "\n",
    "def calculate_word_scores(phraseList):\n",
    "    word_frequency = {}\n",
    "    word_degree = {}\n",
    "    for phrase in phraseList:\n",
    "        word_list = separate_words(phrase)\n",
    "        word_list_length = len(word_list)\n",
    "        word_list_degree = word_list_length - 1\n",
    "        for word in word_list:\n",
    "            word_frequency.setdefault(word, 0)\n",
    "            word_frequency[word] += 1\n",
    "            word_degree.setdefault(word, 0)\n",
    "            word_degree[word] += word_list_degree\n",
    "    for item in word_frequency:\n",
    "        word_degree[item] = word_degree[item] + word_frequency[item]\n",
    "\n",
    "    # Calculate Word scores = deg(w)/frew(w)\n",
    "    word_score = {}\n",
    "    for item in word_frequency:\n",
    "        word_score.setdefault(item, 0)\n",
    "        word_score[item] = word_degree[item] / (word_frequency[item] * 1.0)\n",
    "    return word_score\n",
    "\n",
    "\n",
    "def generate_candidate_keyword_scores(phrase_list, word_score, minFrequency):\n",
    "    keyword_candidates = {}\n",
    "    for phrase in phrase_list:\n",
    "        if phrase_list.count(phrase) >= minFrequency:\n",
    "            keyword_candidates.setdefault(phrase, 0)\n",
    "            word_list = separate_words(phrase)\n",
    "            candidate_score = 0\n",
    "            for word in word_list:\n",
    "                candidate_score += word_score[word]\n",
    "            keyword_candidates[phrase] = candidate_score\n",
    "    return keyword_candidates\n",
    "\n",
    "\n",
    "class Rake(object):\n",
    "    def __init__(self,regex='[\\W\\n]+', minCharacters=1, maxWords=5, minFrequency=1):\n",
    "        #lets users call predefined stopwords easily in a platform agnostic manner or use their own list\n",
    "        if isinstance(stop_words, list):\n",
    "            self.__stop_words_pattern = build_stop_word_regex()\n",
    "        else:\n",
    "            self.__stop_words_pattern = build_stop_word_regex()\n",
    "\n",
    "        self.__minCharacters = minCharacters\n",
    "        self.__maxWords = maxWords\n",
    "        self.__minFrequency = minFrequency\n",
    "\n",
    "    def run(self, text):\n",
    "        sentence_list = split_sentences(text)\n",
    "\n",
    "        phrase_list = generate_candidate_keywords(sentence_list, self.__stop_words_pattern, self.__minCharacters, self.__maxWords)\n",
    "\n",
    "        word_scores = calculate_word_scores(phrase_list)\n",
    "\n",
    "        keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores, self.__minFrequency)\n",
    "\n",
    "        sorted_keywords = sorted(keyword_candidates.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return sorted_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ca22f6dbf7db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrake_object\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mRake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrake_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-ed36c40895ee>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, regex, minCharacters, maxWords, minFrequency)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'[\\W\\n]+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminCharacters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxWords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminFrequency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;31m#lets users call predefined stopwords easily in a platform agnostic manner or use their own list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__stop_words_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_stop_word_regex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "rake_object =Rake(1, 1, 1)\n",
    "keywords = rake_object.run(a)\n",
    "print (keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
